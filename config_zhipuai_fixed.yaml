# ZhipuAI Configuration Example
# This configuration file demonstrates how to configure Magentic-UI to use ZhipuAI models

# Define ZhipuAI client base configuration (using YAML anchor)
zhipuai_base_config: &zhipuai_base_config
  base_url: https://open.bigmodel.cn/api/paas/v4/
  # api_key will be automatically read from environment variable ZHIPUAI_API_KEY
  # Or use: api_key: ${ZHIPUAI_API_KEY}
  api_key: 480a20cc79de40069e54a61b1c320e2f.XALQEr7fgb9duOZU
  max_retries: 10

# Configure models for each agent (using correct field names)
orchestrator_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4.5-air
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.7
    max_tokens: 6000

web_surfer_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4.5-air
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.5
    max_tokens: 6000

coder_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4.5-air
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.3
    max_tokens: 8000

file_surfer_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4.5-air
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.5
    max_tokens: 4000

action_guard_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4-flash
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.1
    max_tokens: 2000

# Plan learning client (for learning plans from historical messages)
plan_learning_client:
  provider: OpenAIChatCompletionClient
  config:
    <<: *zhipuai_base_config
    model: glm-4.5-air
    model_info:
      provider: "zhipuai"
      family: "glm"
      type: "chat_completion"
      vision: false
      function_calling: true
      json_output: true
      structured_output: true
    temperature: 0.7
    max_tokens: 6000

# Other Magentic-UI configuration
cooperative_planning: true
autonomous_execution: false
max_actions_per_step: 5
max_turns: 20
approval_policy: auto-conservative
allow_for_replans: true
do_bing_search: false
websurfer_loop: false

# Usage Instructions:
# 1. Set environment variable:
#    Windows PowerShell: $env:ZHIPUAI_API_KEY="your-api-key"
#    Linux/Mac: export ZHIPUAI_API_KEY="your-api-key"
# 2. Start: magentic-ui --port 8081 --config config_zhipuai_fixed.yaml
#
# Note: Please get a valid API key from ZhipuAI Open Platform
# Platform URL: https://open.bigmodel.cn/
#
# otherwise, you may need to set PYTHONIOENCODING environment variable to utf-8
#  Windows PowerShell: $env:PYTHONIOENCODING = "utf-8"
#  Linux/Mac: export PYTHONIOENCODING="utf-8"
#  magentic-ui --port 8081 --config config_zhipuai_example.yaml